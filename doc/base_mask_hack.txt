We have the longstanding issue with read lengths. Some runs have an extra base added.
Some do not.
Some lanes use the full index.
Some do not.
Occasionally (well, very rarely nowadays) we want to discard bases from just one lane.
In the past we did this via a pre-delivery trim.

Anyway, I'd like to report the real read lengths per lane, as well as the physical
read lengths. This is tricky as I need to account for overridden base masks, so basically
I can't do this until after demultiplexing. I can easily discover the basemask that was
actually used by grepping it out of demultiplexing/laneN/bcl2fastq.opts.

I could translate this into a "264 [8] [8] 58" format but I think just keeping it
as Y264,I8,I8,Y58 is perfectly legible. So how do I get it into:

The e-mail?

This is generated by summarize_lane_contents.py and the assumption is that this only really
changes when the sample sheet changes. We do have the project_real_name() function in there
which goes and does a LIMS/RT query so this script is not devoid of hacks already.

The script is called within run_multiqc() in driver.sh, but only if the
pipeline/sample_summary.yaml is missing. I could call it every time, and have it look for
bcl2fastq.opts, but then that would re-query the project names. I'm thinking maybe I should
break out the project names query into a separate script and save just those. That way I
only have to do it once, and the hackiness is isolated.

Yes, I think I'll do that.

Then what about the text in the MultiQC reports? This is even easier. Just edit
summarize_post_bcl2fastq.py which already reads bcl2fastq.opts. This already accounts
for what to do on the per-lane pages and the summary page.

I may need to explicitly add this to the mulitqc_edgen plugin too? Easy if I do.

I'll do this part first, then worry about the above stuff.

--

OK, so I want a script that just translates project numbers to names. I want to avoid
repeat queries, but I want to query any project I do not have. So, we call the script
with a list of project numbers and a .json file, and an --update flag.
If the --update flag is not set or if there is no .json file in the call, the script
will query the project numbers and dump them out to STDOUT as JSON.

If the JSON file is provided any projects listed there will not be re-queried.

If any project names are queried, and --update is in effect, then the file will be
overwritten (or created) with the new info. Potentially there is a race condition here
but the probability is so low I think we can just discount it and treat it as if the
write is atomic. I think removing the file before writing and then writing in 'x' mode
is technically more reliable - or at least fails with an error not a file corruption.

--

Script is done. Now I need to wire it into the pipeline.

1) Modify summarize_lane_contents.py to get passed this file
2) Re-generate the file before each update
3) Now worry about feeding the basemasks to this script too (just have it scan for
   pipeline/output/demultiplexing/laneN/bcl2fastq.opts)

Oh hang on. Part 2 is problematic because I need the list of projects to get names
for but it's being generated within summarize_lane_contents.py. How did I not spot this
before?
Ah well, in that case I need to modify project_real_names.py to read a sample sheet.
So maybe splitting the functionality out of summarize_lane_contents.py was not so
smart, but I still think disconnecting this from the other logic is better.

OK, I did that but I need to have a reconsider about summarize_lane_contents.py

When I use --from_yaml, should I re-scan the basemask and project names, or should
I just save them into there with all the other data. I think probably the second,
as I can re-scan as often as I like. OK, let's do that.
