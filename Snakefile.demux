#!/bin/bash
# vim: ft=python

## This workflow should be run in a fastqdata/demultiplexing directory to
## drive bcl2fastq. The reason for running here is to get the
## .snakemake and slurm_output dirs in a sensible place.

# Contents >>>
#   + Embedded BASH script to bootstrap the workflow
#   + Initialisation and configuration
#   + Helper functions
#   + The rules specific to this workflow
#   + More generic rules

"""true" ### Begin shell script part
set -euo pipefail

source "`dirname $0`"/shell_helper_functions.sh

# $PATH doesn't get passed to worker nodes on SLURM but I only need it
# for local rules to see programs in this directory. Toolbox path is a separate
# thing and will be added explicitly.
export TOOLBOX="$(find_toolbox)"
export PATH="${PATH}:$(dirname "$0")"

# Caller needs to supply --config lanes='? ? ?' rundir=?
# Apply -F to run all steps every time. Otherwise I could maybe depend on the
# SampleSheet.csv as an input?
snakerun_drmaa "$0" --keep-going -F "$@"

"exit""" ### End of shell script part

#!/usr/bin/env snakemake
import yaml

# The pre-processor needs to find bcl2fastq in the toolbox.
TOOLBOX = 'env PATH="{}:$PATH"'.format(os.environ['TOOLBOX'])

def glob():
    """Regular glob() is useful but it can be improved like so.
    """
    from glob import glob
    return lambda p: sorted( (f.rstrip('/') for f in glob(os.path.expanduser(p))) )
glob = glob()

# Config - must be supplied
LANES = config['lanes'].split()
RUNDIR = config['rundir']

def get_sequential_file(pattern):
    """Given a filename like foo???.log, find the next available filename that
       matches the pattern. The file will be created and left empty.
       I've coded this to avoid race conditions but it's not a problem as
       Snakemake locks the working dir anyway.
    """
    pre, c, post = re.match(r'([^?]*)([?]+)([^?]*)', pattern).groups()

    seqnum = 0

    for existing in glob(pattern):
        try:
            seqnum = int(existing.lstrip(pre).rstrip(post))
        except ValueError:
            pass

    try:
        while True:
            try:
                fh = open('{}{:0{len}d}{}'.format(pre, seqnum, post, len=len(c)), mode='x')
                return fh.name
            except FileExistsError:
                seqnum += 1
    finally:
        fh.close()

# preprocess rule is run for each lane to get the script to run

# bcl2fastq is run for each LANE to produce laneN/Stats/DemuxSummaryF1LN.txt,
# laneN/Stats/DemultiplexingStats.xml and laneN/foo.json

# postprocess rule is run just once to gather and rename all the fastq.gz files
# output is renamesXXX.log where XXX starts at 000.

# It's important for preprocess to run locally so it sees the right $PATH
localrules: preprocess, postprocess

rule postprocess:
    output: 'renames.log', '../projects_ready.txt'
    input: expand("lane{l}/Stats/DemuxSummaryF1L{l}.txt", l=LANES)
    run:
        log_file = get_sequential_file('renames.log.???')
        shell("ln -s {log_file} renames.log")
        shell("BCL2FASTQPostprocessor.py ..")

rule bcl2fastq:
    output:
        summary = "lane{l}/Stats/DemuxSummaryF1L{l}.txt",
        stats = "lane{l}/Stats/DemultiplexingStats.xml",
        json = "lane{l}/Stats/Stats.json"
    input:
        script = "lane{l}/do_demultiplex{l}.sh"
    threads: 12 # if you edit this number, also edit the cluster.yml
    shell:
        #The location for bcl2fastq and input/output should already be coded in the script
        #Log will go to "lane{l}/bcl2fastq.log"
        """set -x
           PROCESSING_THREADS={threads} ; source {input.script}
        """

rule preprocess:
    output:
        script = "lane{l}/do_demultiplex{l}.sh"
    params:
        dest = os.path.abspath('.')
    shell:
        """{TOOLBOX} BCL2FASTQPreprocessor.py {RUNDIR} {params.dest} {wildcards.l}
           mv do_demultiplex{wildcards.l}.sh {output}
        """
